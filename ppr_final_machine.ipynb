{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[54, 43, 35]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 0, 0]\n",
      "[]\n",
      "3\n",
      "3\n",
      "183\n",
      "276\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "imn=\"a.jpg\"\n",
    "\n",
    "#tp['FaceRecords'][0]['Face']['BoundingBox']\n",
    "\n",
    "os.system(\"aws s3 cp \"+imn+\" s3://litmind/a.jpg\")\n",
    "proc = subprocess.Popen(['aws rekognition index-faces --image \"S3Object={Bucket=litmind,Name=a.jpg}\" --region us-east-1 --collection-id \"examplecollection\" --detection-attributes \"ALL\"'], stdout=subprocess.PIPE, shell=True)\n",
    "(out, err) = proc.communicate()\n",
    "\n",
    "\n",
    "proc1 = subprocess.Popen(['aws rekognition detect-labels --image \"S3Object={Bucket=litmind,Name=a.jpg}\" --region us-east-1'], stdout=subprocess.PIPE, shell=True)\n",
    "(out1, err) = proc1.communicate()\n",
    "#print \"program output:\", out\n",
    "\n",
    "import simplejson as json\n",
    "\n",
    "tp=json.loads(out)\n",
    "labels=json.loads(out1)\n",
    "\n",
    "\n",
    "os.system(\"aws s3 rm s3://litmind/a.jpg\")\n",
    "\n",
    "my_json = out.decode('utf8').replace(\"'\", '\"')\n",
    "#print(my_json)\n",
    "#print(out)\n",
    "#print('- '*20)\n",
    "#s = json.dumps(my_json, indent=4, sort_keys=True)\n",
    "#print(s)\n",
    "noOfPeople=0  #no of faces in the pic\n",
    "age=[]\n",
    "emo2d=[]\n",
    "emoConfidence2d=[]\n",
    "gender=[]\n",
    "human=[]\n",
    "kid=[]\n",
    "happy=[]\n",
    "sad=[]\n",
    "angry=[]\n",
    "\n",
    "\n",
    "faceNo=0\n",
    "gen=\"\"\n",
    "emo=[]\n",
    "emoConfidence=[]\n",
    "flagHappy=0\n",
    "flagSad=0\n",
    "flagAngry=0\n",
    "for i in tp['FaceRecords']:\n",
    "\tl_age = tp['FaceRecords'][faceNo]['FaceDetail']['AgeRange']['Low']\n",
    "\th_age = tp['FaceRecords'][faceNo]['FaceDetail']['AgeRange']['High']\n",
    "\tage.append((l_age+h_age)/2)\n",
    "\tgen=(tp['FaceRecords'][faceNo]['FaceDetail']['Gender']['Value'])\n",
    "\tif(gen==\"Female\"):\t\t#Gender- 1 for male, 0 for female\n",
    "\t\tgender.append(0)\n",
    "\telif (gen==\"Male\"):\n",
    "\t\tgender.append(1)\n",
    "\temoNo=0\n",
    "\tfor j in tp['FaceRecords'][faceNo]['FaceDetail']['Emotions']:\n",
    "\t\temo=(tp['FaceRecords'][faceNo]['FaceDetail']['Emotions'][emoNo]['Type'])\n",
    "\t\tif emo==\"HAPPY\":\n",
    "\t\t\tflagHappy=1\n",
    "\t\tif emo==\"SAD\":\n",
    "\t\t\tflagSad=1\n",
    "\t\tif emo==\"ANGRY\":\n",
    "\t\t\tflagAngry=1\n",
    "\t\t#emoConfidence.append(tp['FaceRecords'][faceNo]['FaceDetail']['Emotions'][emoNo]['Confidence'])\n",
    "\t\temoNo+=1\n",
    "\tif(flagHappy==1):\n",
    "\t\thappy.append(1)\n",
    "\telse:\n",
    "\t\thappy.append(0)\n",
    "\tif(flagSad==1):\n",
    "\t\tsad.append(1)\n",
    "\telse:\n",
    "\t\tsad.append(0)\n",
    "\tif(flagAngry==1):\n",
    "\t\tangry.append(1)\n",
    "\telse:\n",
    "\t\tangry.append(0)\n",
    "\t#emo2d.append(emo)\n",
    "\t#emoConfidence2d.append(emoConfidence)\n",
    "\t#emo=[]\n",
    "\t#emoConfidence=[]\n",
    "\tfaceNo+=1\n",
    "noOfPeople=faceNo\n",
    "print noOfPeople\n",
    "print(age)\n",
    "print(happy)\n",
    "print(sad)\n",
    "print(angry)\n",
    "print(gender)\n",
    "\n",
    "def getLabels(labels):\n",
    "\tlabelNo=0\n",
    "\tflagHuman=0\n",
    "\tflagChild=0\n",
    "\tfor i in labels[\"Labels\"]:\n",
    "\t\tname=labels[\"Labels\"][labelNo][\"Name\"]\n",
    "\t\tif((name==\"Person\") or (name==\"People\") or (name==\"Human\")):\n",
    "\t\t\tflagHuman=1\n",
    "\t\tlabelNo+=1\n",
    "\tif(flagHuman==1):\t\t\t\t#Human- 1 for human, 0 for non-human\n",
    "\t\thuman.append(1)\n",
    "\telse:\n",
    "\t\thuman.append(0)\n",
    "\n",
    "faceData=pd.DataFrame()\n",
    "faceData[\"Age\"]=\"NaN\"\n",
    "faceData[\"Happy\"]=\"NaN\"\n",
    "faceData[\"Sad\"]=\"NaN\"\n",
    "faceData[\"Angry\"]=\"NaN\"\n",
    "faceData[\"Gender\"]=\"NaN\"\n",
    "\n",
    "data=[]\n",
    "data2d=[]\n",
    "\n",
    "\n",
    "print(data2d)\n",
    "#getFaceFeatures(tp)\n",
    "#print(labels)\n",
    "getLabels(labels)\n",
    "\n",
    "print noOfPeople\n",
    "\n",
    "for i in range(noOfPeople):\n",
    "\tdata.append(age[i])\n",
    "\tdata.append(happy[i])\n",
    "\tdata.append(sad[i])\n",
    "\tdata.append(angry[i])\n",
    "\tdata.append(gender[i])\n",
    "\tdata2d.append(data)\n",
    "\tdata=[]\n",
    "\n",
    "##cropper\n",
    "print noOfPeople\n",
    "\n",
    "from PIL import Image\n",
    "im=Image.open(imn)\n",
    "width, height = im.size\n",
    "\n",
    "print height\n",
    "print width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face no : 0\n",
      "face no : 1\n",
      "face no : 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for k in range(noOfPeople):\n",
    "    print \"face no : \"+str(k);\n",
    "    p=tp['FaceRecords'][k]['Face']['BoundingBox']\n",
    "    for i in tp['FaceRecords'][k]['FaceDetail']['Landmarks']:\n",
    "\n",
    "        if i['Type']=='eyeLeft':\n",
    "            x1=i['X']*width\n",
    "            y1=i['Y']*height\n",
    "        elif i['Type']=='mouthRight':\n",
    "            x2=i['X']*width\n",
    "            y2=i['Y']*height\n",
    "    x1=x1-p['Width']*width/2.5\n",
    "    x1=x1 if x1>0 else 0;\n",
    "    y1=y1-p['Height']*height/2\n",
    "    y1=y1 if y1>0 else 0;\n",
    "    x2=x2+p['Width']*width/3\n",
    "    x2=x2 if x2<width else width;\n",
    "    y2=y2+p['Height']*height/3\n",
    "    y2=y2 if y2<height else height;\n",
    "    ni=\"f\"+str(k)+\".jpg\"\n",
    "    im.crop((x1, y1,x2, y2)).resize((200, 200), Image.ANTIALIAS).save(ni)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[54, 1, 1, 1, 1], [43, 1, 1, 1, 0], [35, 1, 1, 1, 0]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## CREATE A COLLECTION\n",
    "\n",
    "proc = subprocess.Popen(['aws rekognition create-collection --collection-id \"f\"'], stdout=subprocess.PIPE, shell=True)\n",
    "(out, err) = proc.communicate()\n",
    "\n",
    "## populating a face\n",
    "\n",
    "os.system(\"aws s3 cp f1.jpg s3://litmind/f1.jpg\")\n",
    "\n",
    "proc = subprocess.Popen(['aws rekognition index-faces --image \"S3Object={Bucket=litmind,Name=f1.jpg}\" --region us-east-1 --collection-id \"f\" --detection-attributes \"ALL\" --external-image-id \"GOPAL\"'], stdout=subprocess.PIPE, shell=True)\n",
    "(out, err) = proc.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"aws s3 rm s3://litmind/a.jpg\")\n",
    "os.system(\"aws s3 rm s3://litmind/f1.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    }
   ],
   "source": [
    "for i in range(noOfPeople):\n",
    "    os.system(\"aws s3 cp f\"+str(i)+\".jpg s3://litmind/f\"+str(i)+\".jpg\")\n",
    "    proc = subprocess.Popen(['aws rekognition search-faces-by-image --collection-id \"f\" --image \"S3Object={Bucket =litmind ,Name =f'+str(i)+'.jpg}\"' ], stdout=subprocess.PIPE, shell=True)\n",
    "    (out, err) = proc.communicate()\n",
    "    tp4=json.loads(out)\n",
    "    for j in tp4['FaceMatches']:\n",
    "        if j['Similarity']>90:\n",
    "            print \"hey\" \n",
    "            data2d[i].append(1000)\n",
    "            break\n",
    "##drop the collection\n",
    "proc = subprocess.Popen(['aws rekognition delete-collection --collection-id \"f\"' ], stdout=subprocess.PIPE, shell=True)\n",
    "(out, err) = proc.communicate()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in data2d:\n",
    "    if len(i)==5:\n",
    "        i.append(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[54, 1, 1, 1, 1, 0], [43, 1, 1, 1, 0, 1000], [35, 1, 1, 1, 0, 0]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "\n",
    "model=load_model(\"netite.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "res=[]\n",
    "for i in range(noOfPeople):\n",
    "    res.append(np.argmax(model.predict(np.array(data2d[i]).reshape(1,6))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 0, 3]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0a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\n2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image \n",
    "Image(filename=\"f\"+str(np.argmax(res))+\".jpg\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
